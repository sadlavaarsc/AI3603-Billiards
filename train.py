import os
import json
import argparse
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
import shutil
import gc

# å¯¼å…¥ç°æœ‰æ¨¡å—
from process_raw_match_data import process_match_data
from dual_network import DualNetwork
from data_loader import BilliardsDataset, StatePreprocessor


def train(args):
    """
    è®­ç»ƒåŒç½‘ç»œæ¨¡å‹ï¼ˆæ”¯æŒç»­è®­é¢„è®­ç»ƒæ¨¡å‹ï¼Œå…¼å®¹åµŒå¥—æ¨¡å—æƒé‡æ ¼å¼ï¼‰
    æ ¸å¿ƒä¿®æ”¹ï¼š1.ç­–ç•¥åˆ†æ”¯æ”¹ä¸ºMSEæŸå¤± 2.åˆ é™¤é”™è¯¯æ ‡ç­¾è½¬æ¢ 3.ç­–ç•¥æ ‡ç­¾å³æ—¶å½’ä¸€åŒ–ï¼ˆä¸æ”¹åŠ¨åŸå§‹æ•°æ®ï¼‰
    """
    # 1. å¤„ç†å¯¹å±€æ•°æ®
    if args.use_existing_train_data:
        if not os.path.exists(args.train_data_file):
            raise FileNotFoundError(
                f"æŒ‡å®šçš„è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.train_data_file}")
        print(f"âœ… å¤ç”¨å·²ç”Ÿæˆçš„è®­ç»ƒæ•°æ®: {args.train_data_file}")
    else:
        print(f"Processing match data from {args.match_dir}...")
        process_match_data(args.match_dir, args.train_data_file)
        print(f"Training data generated: {args.train_data_file}")

    # 2. å‡†å¤‡æ•°æ®åŠ è½½
    print("Loading training data...")
    preprocessor = StatePreprocessor()
    temp_data_dir = os.path.join(
        os.path.dirname(args.train_data_file), 'temp_data')
    os.makedirs(temp_data_dir, exist_ok=True)
    temp_data_file = os.path.join(
        temp_data_dir, os.path.basename(args.train_data_file))
    shutil.copy(args.train_data_file, temp_data_file)
    dataset = BilliardsDataset(temp_data_dir, transform=preprocessor)

    num_workers = 0 if torch.cuda.is_available() and os.name == 'nt' else 4
    dataloader = DataLoader(
        dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True if torch.cuda.is_available() else False
    )

    print(f"Dataset size: {len(dataset)}")
    print(f"Batch size: {args.batch_size}")
    print(f"Number of batches: {len(dataloader)}")
    print(f"DataLoader num_workers: {num_workers}")

    # 3. åˆå§‹åŒ–/åŠ è½½æ¨¡å‹ -------------------------- æ ¸å¿ƒä¿®å¤ï¼šé€‚é…åµŒå¥—æ¨¡å—æƒé‡ --------------------------
    print("Initializing/loading dual network model...")
    model = DualNetwork()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    # è®°å½•åˆå§‹Epochï¼ˆç»­è®­æ—¶ä»æŒ‡å®šEpochå¼€å§‹ï¼‰
    start_epoch = 1
    checkpoint = None
    # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
    if args.resume_from:
        if not os.path.exists(args.resume_from):
            raise FileNotFoundError(f"é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.resume_from}")

        # åŠ è½½æ¨¡å‹æ–‡ä»¶
        checkpoint = torch.load(args.resume_from, map_location=device)
        try:
            # å°è¯•1ï¼šåŠ è½½æ–°æ ¼å¼ï¼ˆå¸¦model_state_dictï¼‰
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                model.load_state_dict(
                    checkpoint['model_state_dict'], strict=False)
                if 'epoch' in checkpoint:
                    start_epoch = checkpoint['epoch'] + 1
                print(
                    f"âœ… åŠ è½½æ–°æ ¼å¼é¢„è®­ç»ƒæ¨¡å‹: {args.resume_from}ï¼Œä»Epoch {start_epoch} å¼€å§‹ç»­è®­")
            # å°è¯•2ï¼šåŠ è½½æ—§æ ¼å¼ï¼ˆç›´æ¥æƒé‡ï¼‰
            else:
                # é€‚é…åµŒå¥—æ¨¡å—çš„æƒé‡æ ¼å¼
                model.load_state_dict(checkpoint, strict=False)
                print(f"âœ… åŠ è½½æ—§æ ¼å¼é¢„è®­ç»ƒæ¨¡å‹: {args.resume_from}ï¼ˆå…¼å®¹åµŒå¥—æ¨¡å—ï¼‰")

            # æ‰“å°æƒé‡åŠ è½½æƒ…å†µï¼Œæ–¹ä¾¿è°ƒè¯•
            missing_keys, unexpected_keys = model.load_state_dict(checkpoint['model_state_dict'] if (
                isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint) else checkpoint, strict=False)
            if missing_keys:
                print(f"âš ï¸ æƒé‡ä¸­ç¼ºå¤±çš„é”®ï¼ˆå¯å¿½ç•¥ï¼‰: {missing_keys[:5]}...")  # åªæ‰“å°å‰5ä¸ªé¿å…åˆ·å±
            if unexpected_keys:
                print(f"âš ï¸ æƒé‡ä¸­å¤šä½™çš„é”®ï¼ˆå¯å¿½ç•¥ï¼‰: {unexpected_keys[:5]}...")

        except Exception as e:
            # ç»ˆææ–¹æ¡ˆï¼šæ‰‹åŠ¨éå†æƒé‡ï¼ŒåŒ¹é…å±‚å
            print(f"âš ï¸ ç›´æ¥åŠ è½½æƒé‡å¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨åŒ¹é…: {str(e)}")
            model_dict = model.state_dict()
            # è¿‡æ»¤å‡ºåŒ¹é…çš„æƒé‡
            if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                pretrained_dict = checkpoint['model_state_dict']
            else:
                pretrained_dict = checkpoint

            # é€‚é…åµŒå¥—æ¨¡å—çš„æƒé‡å
            new_pretrained_dict = {}
            for k, v in pretrained_dict.items():
                # å¦‚æœæƒé‡åç›´æ¥åŒ¹é…ï¼Œä¿ç•™
                if k in model_dict:
                    new_pretrained_dict[k] = v
                # å¦‚æœæ˜¯åµŒå¥—æ¨¡å—ï¼ˆå¦‚feature_extractor.spatial_fc1.weightï¼‰
                else:
                    # å°è¯•å»æ‰é¡¶å±‚æ¨¡å—åï¼ˆå¦‚feature_extractor.ï¼‰
                    parts = k.split('.', 1)
                    if len(parts) > 1 and parts[1] in model_dict:
                        new_pretrained_dict[parts[1]] = v
                    # å°è¯•æ·»åŠ é¡¶å±‚æ¨¡å—å
                    elif f"feature_extractor.{k}" in model_dict:
                        new_pretrained_dict[f"feature_extractor.{k}"] = v
                    elif f"policy_head.{k}" in model_dict:
                        new_pretrained_dict[f"policy_head.{k}"] = v
                    elif f"value_head.{k}" in model_dict:
                        new_pretrained_dict[f"value_head.{k}"] = v

            # æ›´æ–°æ¨¡å‹æƒé‡
            model_dict.update(new_pretrained_dict)
            model.load_state_dict(model_dict)
            print("âœ… æ‰‹åŠ¨åŒ¹é…æƒé‡æˆåŠŸï¼Œå¿½ç•¥å±‚åä¸åŒ¹é…çš„éƒ¨åˆ†")
    else:
        print("ğŸ”„ åˆå§‹åŒ–å…¨æ–°æ¨¡å‹ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ")

    print(f"Using device: {device}")

    # 4. å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    # æ ¸å¿ƒä¿®æ”¹1ï¼šç­–ç•¥åˆ†æ”¯æ”¹ä¸ºMSEæŸå¤±ï¼ˆé€‚é…5ç»´è¿ç»­åŠ¨ä½œå›å½’ï¼‰
    policy_criterion = nn.MSELoss()
    value_criterion = nn.MSELoss()

    # ä¼˜åŒ–å™¨
    optimizer = optim.Adam(
        model.parameters(),
        lr=args.learning_rate,
        weight_decay=args.weight_decay
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.StepLR(
        optimizer,
        step_size=args.lr_step_size,
        gamma=args.lr_gamma
    )

    # ç»­è®­æ—¶æ¢å¤ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨çŠ¶æ€ï¼ˆä»…æ–°æ ¼å¼æ”¯æŒï¼‰
    if args.resume_from and checkpoint is not None and 'optimizer_state_dict' in checkpoint:
        try:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            print("âœ… æ¢å¤ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨çŠ¶æ€")
        except:
            print("âš ï¸ æ— æ³•æ¢å¤ä¼˜åŒ–å™¨/è°ƒåº¦å™¨çŠ¶æ€ï¼Œä½¿ç”¨å…¨æ–°çš„ä¼˜åŒ–å™¨é…ç½®")
    elif args.resume_from:
        print("âš ï¸ æ—§æ ¼å¼æ¨¡å‹æ–‡ä»¶æ— ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œä½¿ç”¨å…¨æ–°çš„ä¼˜åŒ–å™¨é…ç½®")

    # 5. è®­ç»ƒå¾ªç¯
    print(f"Starting training from Epoch {start_epoch}...")

    for epoch in range(start_epoch, args.epochs + 1):
        model.train()
        total_policy_loss = 0.0
        total_value_loss = 0.0
        total_loss = 0.0

        with tqdm(dataloader, desc=f"Epoch {epoch}/{args.epochs}") as pbar:
            for batch_idx, (states, policy_targets, value_targets) in enumerate(pbar):
                # æ•°æ®ç§»åˆ°è®¾å¤‡ä¸Š
                states = states.to(device, non_blocking=True)
                policy_targets = policy_targets.to(device, non_blocking=True)
                value_targets = value_targets.to(device, non_blocking=True)

                # æ ¸å¿ƒä¿®æ”¹4ï¼šç­–ç•¥æ ‡ç­¾å³æ—¶å½’ä¸€åŒ–ï¼ˆå…³é”®ï¼ä¸æ”¹åŠ¨åŸå§‹æ•°æ®ï¼Œä»…åœ¨è®¡ç®—æŸå¤±å‰å¤„ç†ï¼‰
                # å®šä¹‰æ¯ä¸ªåŠ¨ä½œç»´åº¦çš„åŸå§‹ç‰©ç†èŒƒå›´ï¼ˆæ ¹æ®ä½ çš„ä¸šåŠ¡é€»è¾‘è°ƒæ•´ï¼‰
                # é€Ÿåº¦/æ°´å¹³è§’/å‚ç›´è§’/xåç§»/yåç§»æœ€å°å€¼
                action_min = torch.tensor(
                    [0.5, 0.0, 0.0, -0.5, -0.5], device=device)
                action_max = torch.tensor(
                    [8.0, 360.0, 90.0, 0.5, 0.5], device=device)  # å¯¹åº”æœ€å¤§å€¼
                # å½’ä¸€åŒ–åˆ°0~1åŒºé—´ï¼ˆåŒ¹é…æ¨¡å‹sigmoidè¾“å‡ºï¼‰
                policy_targets = (policy_targets - action_min) / \
                    (action_max - action_min)
                # è£å‰ªå¼‚å¸¸å€¼ï¼Œé¿å…æ•°æ®é”™è¯¯å¯¼è‡´æŸå¤±å¼‚å¸¸
                policy_targets = torch.clamp(policy_targets, 0.0, 1.0)

                # æ ¸å¿ƒä¿®æ”¹2ï¼šåˆ é™¤é”™è¯¯çš„ç­–ç•¥æ ‡ç­¾æ ¼å¼è½¬æ¢ï¼ˆå·²ç§»é™¤ï¼‰

                # å‰å‘ä¼ æ’­
                outputs = model(states)
                policy_logits = outputs['policy_output']
                value_output = outputs['value_output']

                # è®¡ç®—æŸå¤±ï¼ˆæ­¤æ—¶policy_logitså’Œpolicy_targetséƒ½æ˜¯0~1ï¼Œå°ºåº¦åŒ¹é…ï¼‰
                policy_loss = policy_criterion(policy_logits, policy_targets)
                value_loss = value_criterion(value_output, value_targets)
                loss = args.policy_weight * policy_loss + args.value_weight * value_loss

                # åå‘ä¼ æ’­å’Œä¼˜åŒ–
                optimizer.zero_grad()
                loss.backward()
                if args.clip_grad_norm > 0:
                    torch.nn.utils.clip_grad_norm_(
                        model.parameters(), max_norm=args.clip_grad_norm)
                optimizer.step()

                # ç´¯ç§¯æŸå¤±
                total_policy_loss += policy_loss.item()
                total_value_loss += value_loss.item()
                total_loss += loss.item()

                # æ›´æ–°è¿›åº¦æ¡
                pbar.set_postfix({
                    'Policy Loss': f'{policy_loss.item():.6f}',
                    'Value Loss': f'{value_loss.item():.6f}',
                    'Total Loss': f'{loss.item():.6f}'
                })

        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()

        # æ‰“å° epoch ç»“æœ
        avg_policy_loss = total_policy_loss / len(dataloader)
        avg_value_loss = total_value_loss / len(dataloader)
        avg_total_loss = total_loss / len(dataloader)

        print(f"Epoch {epoch}/{args.epochs}:")
        print(f"  Average Policy Loss: {avg_policy_loss:.6f}")
        print(f"  Average Value Loss: {avg_value_loss:.6f}")
        print(f"  Average Total Loss: {avg_total_loss:.6f}")
        print(f"  Learning Rate: {optimizer.param_groups[0]['lr']}")

        # ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹ï¼ˆæ–°æ ¼å¼ï¼ŒåŒ…å«å®Œæ•´çŠ¶æ€ï¼‰
        if epoch % args.save_interval == 0 or epoch == args.epochs:
            checkpoint_path = os.path.join(
                args.model_dir, f"dual_network_epoch_{epoch}.pt")
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'scheduler_state_dict': scheduler.state_dict(),
                'policy_loss': avg_policy_loss,
                'value_loss': avg_value_loss
            }, checkpoint_path)
            print(f"Model checkpoint saved: {checkpoint_path}")

        # æ¸…ç†å†…å­˜
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹ï¼ˆæ–°æ ¼å¼ï¼‰
    final_model_path = os.path.join(args.model_dir, "dual_network_final.pt")
    torch.save({
        'epoch': args.epochs,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'scheduler_state_dict': scheduler.state_dict()
    }, final_model_path)
    print(f"Final model saved: {final_model_path}")

    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    shutil.rmtree(temp_data_dir, ignore_errors=True)
    print("Training completed!")


def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(
        description="Train dual network model (support resume training)")

    # æ•°æ®ç›¸å…³å‚æ•°
    parser.add_argument('--match_dir', type=str, default='match_data',
                        help='Directory containing match data files')
    parser.add_argument('--train_data_file', type=str, default='trainable_data.json',
                        help='Output file path for trainable data')
    parser.add_argument('--use_existing_train_data', action='store_true',
                        help='Use existing trainable_data.json (skip reprocessing)')

    # æ¨¡å‹ç›¸å…³å‚æ•°
    parser.add_argument('--model_dir', type=str, default='models',
                        help='Directory to save trained models')
    parser.add_argument('--resume_from', type=str, default='',
                        help='Path to pre-trained model (e.g., models/dual_network_epoch_100.pt) for resume training')

    # è®­ç»ƒç›¸å…³å‚æ•°
    parser.add_argument('--epochs', type=int, default=100,
                        help='Total number of training epochs (include resumed epochs)')
    parser.add_argument('--batch_size', type=int, default=64,
                        help='Batch size for training')
    parser.add_argument('--learning_rate', type=float, default=1e-4,
                        help='Learning rate')
    parser.add_argument('--weight_decay', type=float, default=1e-5,
                        help='Weight decay for regularization')
    parser.add_argument('--lr_step_size', type=int, default=50,
                        help='Step size for learning rate decay')
    parser.add_argument('--lr_gamma', type=float, default=0.5,
                        help='Gamma value for learning rate decay')
    parser.add_argument('--save_interval', type=int, default=20,
                        help='Interval for saving model checkpoints')
    # æ ¸å¿ƒä¿®æ”¹3ï¼šè°ƒæ•´æŸå¤±æƒé‡é»˜è®¤å€¼ï¼ˆé€‚é…MSEæŸå¤±ï¼‰
    parser.add_argument('--policy_weight', type=float, default=5.0,  # å½’ä¸€åŒ–åè°ƒä¸º5.0æ›´åˆç†
                        help='Weight for policy loss (balance with value loss)')
    parser.add_argument('--value_weight', type=float, default=1.0,
                        help='Weight for value loss (balance with policy loss)')
    parser.add_argument('--clip_grad_norm', type=float, default=1.0,
                        help='Max norm for gradient clipping (0 to disable)')

    args = parser.parse_args()

    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs(args.model_dir, exist_ok=True)

    # å¼€å§‹è®­ç»ƒ
    train(args)


if __name__ == '__main__':
    main()
